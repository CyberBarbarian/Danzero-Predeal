{
  "config": {
    "num_workers": 150,
    "num_envs_per_worker": 4,
    "total_envs": 600,
    "num_iterations": 300
  },
  "start_time": "2025-10-09T19:59:59.989519",
  "init_time": 28.590646982192993,
  "iterations": [
    {
      "iteration": 1,
      "timestamp": 1760011209.7671833,
      "duration": 9.777601480484009,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 0.0
    },
    {
      "iteration": 2,
      "timestamp": 1760011217.7905557,
      "duration": 8.023202419281006,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 0.0
    },
    {
      "iteration": 3,
      "timestamp": 1760011224.0764387,
      "duration": 6.285867929458618,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 551.0
    },
    {
      "iteration": 4,
      "timestamp": 1760011231.5370317,
      "duration": 7.460575103759766,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 617.3333333333334
    },
    {
      "iteration": 5,
      "timestamp": 1760011238.9078248,
      "duration": 7.370773553848267,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.5
    },
    {
      "iteration": 6,
      "timestamp": 1760011245.2771506,
      "duration": 6.369308948516846,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.5
    },
    {
      "iteration": 7,
      "timestamp": 1760011253.26087,
      "duration": 7.983699321746826,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 665.6
    },
    {
      "iteration": 8,
      "timestamp": 1760011259.6718054,
      "duration": 6.4109179973602295,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 734.375
    },
    {
      "iteration": 9,
      "timestamp": 1760011267.3532636,
      "duration": 7.68143630027771,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 734.375
    },
    {
      "iteration": 10,
      "timestamp": 1760011274.6940525,
      "duration": 7.340766429901123,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 722.8888888888889
    },
    {
      "iteration": 11,
      "timestamp": 1760011281.0672874,
      "duration": 6.372889041900635,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 722.8888888888889
    },
    {
      "iteration": 12,
      "timestamp": 1760011288.5785913,
      "duration": 7.51128888130188,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 705.5
    },
    {
      "iteration": 13,
      "timestamp": 1760011296.036025,
      "duration": 7.457415342330933,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.5384615384615
    },
    {
      "iteration": 14,
      "timestamp": 1760011303.0423448,
      "duration": 7.006300687789917,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.5384615384615
    },
    {
      "iteration": 15,
      "timestamp": 1760011310.6523077,
      "duration": 7.609934329986572,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 715.5
    },
    {
      "iteration": 16,
      "timestamp": 1760011318.1945045,
      "duration": 7.542162656784058,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 710.75
    },
    {
      "iteration": 17,
      "timestamp": 1760011325.5837624,
      "duration": 7.389234781265259,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 722.5882352941177
    },
    {
      "iteration": 18,
      "timestamp": 1760011332.0086977,
      "duration": 6.424914121627808,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 722.5882352941177
    },
    {
      "iteration": 19,
      "timestamp": 1760011338.941283,
      "duration": 6.932564973831177,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 698.25
    },
    {
      "iteration": 20,
      "timestamp": 1760011346.9820046,
      "duration": 8.040700435638428,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 717.1904761904761
    },
    {
      "iteration": 21,
      "timestamp": 1760011353.3511906,
      "duration": 6.368814706802368,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 717.1904761904761
    },
    {
      "iteration": 22,
      "timestamp": 1760011360.8748164,
      "duration": 7.523605823516846,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.0869565217391
    },
    {
      "iteration": 23,
      "timestamp": 1760011368.3411503,
      "duration": 7.466314315795898,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.0869565217391
    },
    {
      "iteration": 24,
      "timestamp": 1760011375.2296293,
      "duration": 6.888457775115967,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 704.2
    },
    {
      "iteration": 25,
      "timestamp": 1760011382.1294208,
      "duration": 6.899768352508545,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 705.7037037037037
    },
    {
      "iteration": 26,
      "timestamp": 1760011390.6047611,
      "duration": 8.475321769714355,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 692.7142857142857
    },
    {
      "iteration": 27,
      "timestamp": 1760011397.0126762,
      "duration": 6.407896041870117,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 690.4137931034483
    },
    {
      "iteration": 28,
      "timestamp": 1760011404.517848,
      "duration": 7.50514817237854,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.0333333333333
    },
    {
      "iteration": 29,
      "timestamp": 1760011411.4390068,
      "duration": 6.921135663986206,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.3225806451613
    },
    {
      "iteration": 30,
      "timestamp": 1760011418.3572302,
      "duration": 6.918203353881836,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 689.5151515151515
    },
    {
      "iteration": 31,
      "timestamp": 1760011426.466471,
      "duration": 8.1088707447052,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 689.5151515151515
    },
    {
      "iteration": 32,
      "timestamp": 1760011433.335559,
      "duration": 6.869068622589111,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.6176470588235
    },
    {
      "iteration": 33,
      "timestamp": 1760011440.2722352,
      "duration": 6.936652421951294,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.3888888888889
    },
    {
      "iteration": 34,
      "timestamp": 1760011447.229325,
      "duration": 6.957066297531128,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.9736842105264
    },
    {
      "iteration": 35,
      "timestamp": 1760011454.1189878,
      "duration": 6.889636993408203,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.9736842105264
    },
    {
      "iteration": 36,
      "timestamp": 1760011461.041085,
      "duration": 6.922077655792236,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 686.375
    },
    {
      "iteration": 37,
      "timestamp": 1760011469.039718,
      "duration": 7.9986114501953125,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 688.1463414634146
    },
    {
      "iteration": 38,
      "timestamp": 1760011476.5675037,
      "duration": 7.52775502204895,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.2954545454545
    },
    {
      "iteration": 39,
      "timestamp": 1760011482.863216,
      "duration": 6.295689344406128,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.2954545454545
    },
    {
      "iteration": 40,
      "timestamp": 1760011490.4064715,
      "duration": 7.54323410987854,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.2954545454545
    },
    {
      "iteration": 41,
      "timestamp": 1760011498.2329028,
      "duration": 7.825981140136719,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 678.4468085106383
    },
    {
      "iteration": 42,
      "timestamp": 1760011504.5795352,
      "duration": 6.34661340713501,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.375
    },
    {
      "iteration": 43,
      "timestamp": 1760011512.5747955,
      "duration": 7.995208263397217,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 675.6938775510204
    },
    {
      "iteration": 44,
      "timestamp": 1760011518.8900228,
      "duration": 6.315203428268433,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 671.1176470588235
    },
    {
      "iteration": 45,
      "timestamp": 1760011526.4688578,
      "duration": 7.578810453414917,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 671.1176470588235
    },
    {
      "iteration": 46,
      "timestamp": 1760011532.798965,
      "duration": 6.330075263977051,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 667.2075471698113
    },
    {
      "iteration": 47,
      "timestamp": 1760011540.8130984,
      "duration": 8.014110803604126,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 667.5370370370371
    },
    {
      "iteration": 48,
      "timestamp": 1760011547.628117,
      "duration": 6.814992189407349,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 671.0727272727273
    },
    {
      "iteration": 49,
      "timestamp": 1760011555.187744,
      "duration": 7.5596022605896,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 666.9473684210526
    },
    {
      "iteration": 50,
      "timestamp": 1760011561.9783695,
      "duration": 6.790598630905151,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 671.1379310344828
    },
    {
      "iteration": 51,
      "timestamp": 1760011568.9565995,
      "duration": 6.971010684967041,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 669.5932203389831
    },
    {
      "iteration": 52,
      "timestamp": 1760011576.9000728,
      "duration": 7.943449974060059,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 669.5166666666667
    },
    {
      "iteration": 53,
      "timestamp": 1760011583.3814595,
      "duration": 6.481362581253052,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 669.5166666666667
    },
    {
      "iteration": 54,
      "timestamp": 1760011590.8656733,
      "duration": 7.484189510345459,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 669.5166666666667
    },
    {
      "iteration": 55,
      "timestamp": 1760011597.752521,
      "duration": 6.886819124221802,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 681.4603174603175
    },
    {
      "iteration": 56,
      "timestamp": 1760011605.4607916,
      "duration": 7.708254098892212,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 681.4603174603175
    },
    {
      "iteration": 57,
      "timestamp": 1760011612.9257803,
      "duration": 7.4649658203125,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 685.276923076923
    },
    {
      "iteration": 58,
      "timestamp": 1760011619.3336325,
      "duration": 6.407829523086548,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 683.8030303030303
    },
    {
      "iteration": 59,
      "timestamp": 1760011627.4302998,
      "duration": 8.096640348434448,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 683.2089552238806
    },
    {
      "iteration": 60,
      "timestamp": 1760011633.7457242,
      "duration": 6.315401077270508,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 683.2089552238806
    },
    {
      "iteration": 61,
      "timestamp": 1760011641.194769,
      "duration": 7.44879937171936,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 681.9420289855072
    },
    {
      "iteration": 62,
      "timestamp": 1760011647.5288467,
      "duration": 6.334054470062256,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 685.6901408450705
    },
    {
      "iteration": 63,
      "timestamp": 1760011654.964497,
      "duration": 7.435631275177002,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 685.6901408450705
    },
    {
      "iteration": 64,
      "timestamp": 1760011661.9012797,
      "duration": 6.93675971031189,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 685.6901408450705
    },
    {
      "iteration": 65,
      "timestamp": 1760011669.8879702,
      "duration": 7.9866602420806885,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 690.0405405405405
    },
    {
      "iteration": 66,
      "timestamp": 1760011676.8511462,
      "duration": 6.963151931762695,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 690.0405405405405
    },
    {
      "iteration": 67,
      "timestamp": 1760011684.283519,
      "duration": 7.432344436645508,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 688.671052631579
    },
    {
      "iteration": 68,
      "timestamp": 1760011691.2888193,
      "duration": 7.0052735805511475,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 688.671052631579
    },
    {
      "iteration": 69,
      "timestamp": 1760011699.3469634,
      "duration": 8.058117866516113,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.0
    },
    {
      "iteration": 70,
      "timestamp": 1760011705.7408392,
      "duration": 6.393848419189453,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 694.5949367088608
    },
    {
      "iteration": 71,
      "timestamp": 1760011713.1972444,
      "duration": 7.45602011680603,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.5625
    },
    {
      "iteration": 72,
      "timestamp": 1760011720.8660848,
      "duration": 7.668816566467285,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.5625
    },
    {
      "iteration": 73,
      "timestamp": 1760011727.3239412,
      "duration": 6.457827806472778,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.5625
    },
    {
      "iteration": 74,
      "timestamp": 1760011734.6954238,
      "duration": 7.37145733833313,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 697.4691358024692
    },
    {
      "iteration": 75,
      "timestamp": 1760011742.1808505,
      "duration": 7.485398769378662,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 706.1904761904761
    },
    {
      "iteration": 76,
      "timestamp": 1760011749.0626888,
      "duration": 6.8818137645721436,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.9411764705883
    },
    {
      "iteration": 77,
      "timestamp": 1760011756.5759683,
      "duration": 7.513253927230835,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.9411764705883
    },
    {
      "iteration": 78,
      "timestamp": 1760011763.9698062,
      "duration": 7.393807649612427,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.1954022988506
    },
    {
      "iteration": 79,
      "timestamp": 1760011770.3528125,
      "duration": 6.3829803466796875,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 700.4431818181819
    },
    {
      "iteration": 80,
      "timestamp": 1760011778.294012,
      "duration": 7.94117546081543,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 704.8651685393259
    },
    {
      "iteration": 81,
      "timestamp": 1760011785.1869445,
      "duration": 6.892489194869995,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.7
    },
    {
      "iteration": 82,
      "timestamp": 1760011792.1151583,
      "duration": 6.928185701370239,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.7
    },
    {
      "iteration": 83,
      "timestamp": 1760011799.5349283,
      "duration": 7.419739007949829,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.8478260869565
    },
    {
      "iteration": 84,
      "timestamp": 1760011806.511335,
      "duration": 6.976382732391357,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.1075268817204
    },
    {
      "iteration": 85,
      "timestamp": 1760011813.4536884,
      "duration": 6.942328214645386,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 704.6631578947369
    },
    {
      "iteration": 86,
      "timestamp": 1760011821.4076443,
      "duration": 7.953927993774414,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 704.8645833333334
    },
    {
      "iteration": 87,
      "timestamp": 1760011829.050397,
      "duration": 7.642730474472046,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.4329896907217
    },
    {
      "iteration": 88,
      "timestamp": 1760011835.5560853,
      "duration": 6.505663156509399,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.8181818181819
    },
    {
      "iteration": 89,
      "timestamp": 1760011843.0151663,
      "duration": 7.45905327796936,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.8181818181819
    },
    {
      "iteration": 90,
      "timestamp": 1760011849.8355033,
      "duration": 6.820308208465576,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 700.88
    },
    {
      "iteration": 91,
      "timestamp": 1760011856.7239895,
      "duration": 6.888117551803589,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.0
    },
    {
      "iteration": 92,
      "timestamp": 1760011864.1231477,
      "duration": 7.399124622344971,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 702.77
    },
    {
      "iteration": 93,
      "timestamp": 1760011870.508185,
      "duration": 6.385004281997681,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 702.77
    },
    {
      "iteration": 94,
      "timestamp": 1760011878.0271022,
      "duration": 7.518881797790527,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 702.3
    },
    {
      "iteration": 95,
      "timestamp": 1760011885.5078373,
      "duration": 7.480709552764893,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 698.03
    },
    {
      "iteration": 96,
      "timestamp": 1760011891.9688041,
      "duration": 6.460938453674316,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.35
    },
    {
      "iteration": 97,
      "timestamp": 1760011899.416348,
      "duration": 7.447515487670898,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 693.89
    },
    {
      "iteration": 98,
      "timestamp": 1760011906.8057065,
      "duration": 7.389324426651001,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 692.79
    },
    {
      "iteration": 99,
      "timestamp": 1760011913.2392287,
      "duration": 6.433490037918091,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 692.79
    },
    {
      "iteration": 100,
      "timestamp": 1760011921.2194614,
      "duration": 7.980199337005615,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 694.61
    },
    {
      "iteration": 101,
      "timestamp": 1760011928.0871122,
      "duration": 6.860105037689209,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 694.82
    },
    {
      "iteration": 102,
      "timestamp": 1760011934.956518,
      "duration": 6.869380474090576,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.77
    },
    {
      "iteration": 103,
      "timestamp": 1760011942.3309803,
      "duration": 7.374437570571899,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.77
    },
    {
      "iteration": 104,
      "timestamp": 1760011948.9326417,
      "duration": 6.601629972457886,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 690.38
    },
    {
      "iteration": 105,
      "timestamp": 1760011956.869858,
      "duration": 7.937187910079956,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.91
    },
    {
      "iteration": 106,
      "timestamp": 1760011963.6828644,
      "duration": 6.812984943389893,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 698.1
    },
    {
      "iteration": 107,
      "timestamp": 1760011970.582685,
      "duration": 6.899796724319458,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.26
    },
    {
      "iteration": 108,
      "timestamp": 1760011977.997424,
      "duration": 7.414715528488159,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.26
    },
    {
      "iteration": 109,
      "timestamp": 1760011984.3528447,
      "duration": 6.355395555496216,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.36
    },
    {
      "iteration": 110,
      "timestamp": 1760011991.7399378,
      "duration": 7.3870673179626465,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 700.4
    },
    {
      "iteration": 111,
      "timestamp": 1760011999.5977657,
      "duration": 7.857459783554077,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.9
    },
    {
      "iteration": 112,
      "timestamp": 1760012005.3485706,
      "duration": 5.750784158706665,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.38
    },
    {
      "iteration": 113,
      "timestamp": 1760012013.4923306,
      "duration": 8.14373517036438,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.11
    },
    {
      "iteration": 114,
      "timestamp": 1760012020.9186308,
      "duration": 7.426267862319946,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.44
    },
    {
      "iteration": 115,
      "timestamp": 1760012027.2889512,
      "duration": 6.370291709899902,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.44
    },
    {
      "iteration": 116,
      "timestamp": 1760012035.389533,
      "duration": 8.100555658340454,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.25
    },
    {
      "iteration": 117,
      "timestamp": 1760012043.373682,
      "duration": 7.984119415283203,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 697.98
    },
    {
      "iteration": 118,
      "timestamp": 1760012049.6855333,
      "duration": 6.311824798583984,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 697.98
    },
    {
      "iteration": 119,
      "timestamp": 1760012057.2470064,
      "duration": 7.561443090438843,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.07
    },
    {
      "iteration": 120,
      "timestamp": 1760012064.877597,
      "duration": 7.630566835403442,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.71
    },
    {
      "iteration": 121,
      "timestamp": 1760012071.2299242,
      "duration": 6.351966142654419,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.9
    },
    {
      "iteration": 122,
      "timestamp": 1760012078.6930537,
      "duration": 7.463102102279663,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.04
    },
    {
      "iteration": 123,
      "timestamp": 1760012086.1603487,
      "duration": 7.467263221740723,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.05
    },
    {
      "iteration": 124,
      "timestamp": 1760012093.0795763,
      "duration": 6.919202566146851,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.08
    },
    {
      "iteration": 125,
      "timestamp": 1760012100.5982425,
      "duration": 7.518639802932739,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.3
    },
    {
      "iteration": 126,
      "timestamp": 1760012106.8979354,
      "duration": 6.299660921096802,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 697.85
    },
    {
      "iteration": 127,
      "timestamp": 1760012114.303568,
      "duration": 7.405607223510742,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 697.37
    },
    {
      "iteration": 128,
      "timestamp": 1760012122.3409157,
      "duration": 8.037314653396606,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.01
    },
    {
      "iteration": 129,
      "timestamp": 1760012128.7391777,
      "duration": 6.398234128952026,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.01
    },
    {
      "iteration": 130,
      "timestamp": 1760012136.8843188,
      "duration": 8.145110845565796,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.99
    },
    {
      "iteration": 131,
      "timestamp": 1760012143.3217437,
      "duration": 6.4370036125183105,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 694.69
    },
    {
      "iteration": 132,
      "timestamp": 1760012150.7714996,
      "duration": 7.449733018875122,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.78
    },
    {
      "iteration": 133,
      "timestamp": 1760012158.2292163,
      "duration": 7.457692861557007,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.12
    },
    {
      "iteration": 134,
      "timestamp": 1760012164.5573096,
      "duration": 6.32805871963501,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.12
    },
    {
      "iteration": 135,
      "timestamp": 1760012172.8314493,
      "duration": 8.274104118347168,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 704.14
    },
    {
      "iteration": 136,
      "timestamp": 1760012179.7692497,
      "duration": 6.9377758502960205,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 705.14
    },
    {
      "iteration": 137,
      "timestamp": 1760012187.2216907,
      "duration": 7.452422142028809,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 705.99
    },
    {
      "iteration": 138,
      "timestamp": 1760012195.1773596,
      "duration": 7.955641984939575,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.75
    },
    {
      "iteration": 139,
      "timestamp": 1760012200.9575,
      "duration": 5.780108451843262,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.75
    },
    {
      "iteration": 140,
      "timestamp": 1760012208.9776175,
      "duration": 8.020081520080566,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.93
    },
    {
      "iteration": 141,
      "timestamp": 1760012216.3115451,
      "duration": 7.333522081375122,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.93
    },
    {
      "iteration": 142,
      "timestamp": 1760012223.2493212,
      "duration": 6.937748670578003,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 694.84
    },
    {
      "iteration": 143,
      "timestamp": 1760012230.7146099,
      "duration": 7.465260744094849,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 692.61
    },
    {
      "iteration": 144,
      "timestamp": 1760012237.1027074,
      "duration": 6.388067722320557,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 692.61
    },
    {
      "iteration": 145,
      "timestamp": 1760012245.098687,
      "duration": 7.995952367782593,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 694.23
    },
    {
      "iteration": 146,
      "timestamp": 1760012251.5181794,
      "duration": 6.419463157653809,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 698.13
    },
    {
      "iteration": 147,
      "timestamp": 1760012259.0096974,
      "duration": 7.491494178771973,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 698.13
    },
    {
      "iteration": 148,
      "timestamp": 1760012265.39638,
      "duration": 6.386651277542114,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.6
    },
    {
      "iteration": 149,
      "timestamp": 1760012273.1571019,
      "duration": 7.760690450668335,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 693.9
    },
    {
      "iteration": 150,
      "timestamp": 1760012280.5853422,
      "duration": 7.4282073974609375,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.2
    },
    {
      "iteration": 151,
      "timestamp": 1760012286.9257073,
      "duration": 6.332495927810669,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.2
    },
    {
      "iteration": 152,
      "timestamp": 1760012294.889162,
      "duration": 7.963422775268555,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 693.24
    },
    {
      "iteration": 153,
      "timestamp": 1760012301.7226298,
      "duration": 6.833436727523804,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 692.95
    },
    {
      "iteration": 154,
      "timestamp": 1760012308.7786365,
      "duration": 7.055977821350098,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 692.95
    },
    {
      "iteration": 155,
      "timestamp": 1760012316.7195227,
      "duration": 7.940854549407959,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 687.96
    },
    {
      "iteration": 156,
      "timestamp": 1760012322.68031,
      "duration": 5.9607555866241455,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 684.82
    },
    {
      "iteration": 157,
      "timestamp": 1760012330.5704658,
      "duration": 7.890129566192627,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.01
    },
    {
      "iteration": 158,
      "timestamp": 1760012336.4831357,
      "duration": 5.9126176834106445,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.01
    },
    {
      "iteration": 159,
      "timestamp": 1760012343.967169,
      "duration": 7.484001636505127,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 682.01
    },
    {
      "iteration": 160,
      "timestamp": 1760012351.853278,
      "duration": 7.886086940765381,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 681.87
    },
    {
      "iteration": 161,
      "timestamp": 1760012358.8769686,
      "duration": 7.023330211639404,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 681.56
    },
    {
      "iteration": 162,
      "timestamp": 1760012365.8463695,
      "duration": 6.969378471374512,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 685.66
    },
    {
      "iteration": 163,
      "timestamp": 1760012373.4680777,
      "duration": 7.621685028076172,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 685.42
    },
    {
      "iteration": 164,
      "timestamp": 1760012380.8367424,
      "duration": 7.368638515472412,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 680.74
    },
    {
      "iteration": 165,
      "timestamp": 1760012388.289762,
      "duration": 7.452987194061279,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 680.74
    },
    {
      "iteration": 166,
      "timestamp": 1760012394.668113,
      "duration": 6.378317594528198,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 680.45
    },
    {
      "iteration": 167,
      "timestamp": 1760012402.1788714,
      "duration": 7.510727405548096,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 680.45
    },
    {
      "iteration": 168,
      "timestamp": 1760012408.5375962,
      "duration": 6.3586883544921875,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 679.18
    },
    {
      "iteration": 169,
      "timestamp": 1760012416.578752,
      "duration": 8.04112696647644,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 679.18
    },
    {
      "iteration": 170,
      "timestamp": 1760012424.0701,
      "duration": 7.491300582885742,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 689.96
    },
    {
      "iteration": 171,
      "timestamp": 1760012430.3991485,
      "duration": 6.328694105148315,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 688.16
    },
    {
      "iteration": 172,
      "timestamp": 1760012437.9363277,
      "duration": 7.537152528762817,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 689.81
    },
    {
      "iteration": 173,
      "timestamp": 1760012444.8502216,
      "duration": 6.913863658905029,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 690.88
    },
    {
      "iteration": 174,
      "timestamp": 1760012451.8391228,
      "duration": 6.988871335983276,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 686.51
    },
    {
      "iteration": 175,
      "timestamp": 1760012459.2647953,
      "duration": 7.4256486892700195,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 686.51
    },
    {
      "iteration": 176,
      "timestamp": 1760012465.6017504,
      "duration": 6.336923360824585,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 689.38
    },
    {
      "iteration": 177,
      "timestamp": 1760012473.6160765,
      "duration": 8.014295101165771,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 684.21
    },
    {
      "iteration": 178,
      "timestamp": 1760012481.0296361,
      "duration": 7.413532495498657,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 684.21
    },
    {
      "iteration": 179,
      "timestamp": 1760012487.3975792,
      "duration": 6.367910861968994,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 684.21
    },
    {
      "iteration": 180,
      "timestamp": 1760012494.5570698,
      "duration": 7.159460783004761,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 685.78
    },
    {
      "iteration": 181,
      "timestamp": 1760012502.013925,
      "duration": 7.456509113311768,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 694.47
    },
    {
      "iteration": 182,
      "timestamp": 1760012508.3931832,
      "duration": 6.379232168197632,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 694.47
    },
    {
      "iteration": 183,
      "timestamp": 1760012515.840027,
      "duration": 7.446818828582764,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.46
    },
    {
      "iteration": 184,
      "timestamp": 1760012523.718695,
      "duration": 7.878641366958618,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.46
    },
    {
      "iteration": 185,
      "timestamp": 1760012529.5623107,
      "duration": 5.843586206436157,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 698.17
    },
    {
      "iteration": 186,
      "timestamp": 1760012537.533489,
      "duration": 7.9711503982543945,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.59
    },
    {
      "iteration": 187,
      "timestamp": 1760012543.8340137,
      "duration": 6.300499677658081,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 698.14
    },
    {
      "iteration": 188,
      "timestamp": 1760012551.3647773,
      "duration": 7.530732154846191,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 697.66
    },
    {
      "iteration": 189,
      "timestamp": 1760012559.4096303,
      "duration": 8.044824361801147,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 695.56
    },
    {
      "iteration": 190,
      "timestamp": 1760012565.2553573,
      "duration": 5.8456950187683105,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 696.11
    },
    {
      "iteration": 191,
      "timestamp": 1760012573.2858045,
      "duration": 8.030064344406128,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 693.9
    },
    {
      "iteration": 192,
      "timestamp": 1760012580.6561282,
      "duration": 7.370292663574219,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 693.9
    },
    {
      "iteration": 193,
      "timestamp": 1760012587.5948496,
      "duration": 6.938690662384033,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 687.01
    },
    {
      "iteration": 194,
      "timestamp": 1760012595.0225894,
      "duration": 7.427711725234985,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 693.4
    },
    {
      "iteration": 195,
      "timestamp": 1760012601.3609116,
      "duration": 6.338293075561523,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.83
    },
    {
      "iteration": 196,
      "timestamp": 1760012609.1384377,
      "duration": 7.777498006820679,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.83
    },
    {
      "iteration": 197,
      "timestamp": 1760012616.0988379,
      "duration": 6.960371255874634,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.67
    },
    {
      "iteration": 198,
      "timestamp": 1760012623.5677505,
      "duration": 7.468881845474243,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.15
    },
    {
      "iteration": 199,
      "timestamp": 1760012631.0478237,
      "duration": 7.480046033859253,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.15
    },
    {
      "iteration": 200,
      "timestamp": 1760012637.451764,
      "duration": 6.403910160064697,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 691.15
    },
    {
      "iteration": 201,
      "timestamp": 1760012644.3466403,
      "duration": 6.885674953460693,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 688.44
    },
    {
      "iteration": 202,
      "timestamp": 1760012652.3556242,
      "duration": 8.008953332901001,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.07
    },
    {
      "iteration": 203,
      "timestamp": 1760012659.1637485,
      "duration": 6.808103799819946,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.42
    },
    {
      "iteration": 204,
      "timestamp": 1760012666.1169071,
      "duration": 6.953125715255737,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 699.42
    },
    {
      "iteration": 205,
      "timestamp": 1760012673.5001864,
      "duration": 7.383247137069702,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.37
    },
    {
      "iteration": 206,
      "timestamp": 1760012680.4215147,
      "duration": 6.9213032722473145,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 701.37
    },
    {
      "iteration": 207,
      "timestamp": 1760012687.325904,
      "duration": 6.904369115829468,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.14
    },
    {
      "iteration": 208,
      "timestamp": 1760012694.1657672,
      "duration": 6.83984112739563,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.14
    },
    {
      "iteration": 209,
      "timestamp": 1760012701.0898576,
      "duration": 6.924060344696045,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 704.49
    },
    {
      "iteration": 210,
      "timestamp": 1760012709.0800052,
      "duration": 7.990119457244873,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.66
    },
    {
      "iteration": 211,
      "timestamp": 1760012715.3317754,
      "duration": 6.251416921615601,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 703.66
    },
    {
      "iteration": 212,
      "timestamp": 1760012722.872236,
      "duration": 7.540429592132568,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 704.83
    },
    {
      "iteration": 213,
      "timestamp": 1760012730.526118,
      "duration": 7.6538496017456055,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 708.45
    },
    {
      "iteration": 214,
      "timestamp": 1760012736.9034336,
      "duration": 6.377288818359375,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 709.21
    },
    {
      "iteration": 215,
      "timestamp": 1760012744.9184155,
      "duration": 8.014953851699829,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 707.73
    },
    {
      "iteration": 216,
      "timestamp": 1760012751.2604616,
      "duration": 6.3420257568359375,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 707.73
    },
    {
      "iteration": 217,
      "timestamp": 1760012758.7860563,
      "duration": 7.525559663772583,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 716.76
    },
    {
      "iteration": 218,
      "timestamp": 1760012765.7067554,
      "duration": 6.920668840408325,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 722.55
    },
    {
      "iteration": 219,
      "timestamp": 1760012773.214477,
      "duration": 7.507688760757446,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 722.55
    },
    {
      "iteration": 220,
      "timestamp": 1760012780.619909,
      "duration": 7.40540075302124,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.31
    },
    {
      "iteration": 221,
      "timestamp": 1760012787.4894242,
      "duration": 6.869146823883057,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 726.52
    },
    {
      "iteration": 222,
      "timestamp": 1760012794.4351575,
      "duration": 6.945706129074097,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 726.52
    },
    {
      "iteration": 223,
      "timestamp": 1760012801.775962,
      "duration": 7.340783596038818,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.23
    },
    {
      "iteration": 224,
      "timestamp": 1760012808.6781828,
      "duration": 6.902195453643799,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 729.33
    },
    {
      "iteration": 225,
      "timestamp": 1760012815.5847297,
      "duration": 6.906517505645752,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 729.33
    },
    {
      "iteration": 226,
      "timestamp": 1760012822.793539,
      "duration": 7.208785057067871,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 722.9
    },
    {
      "iteration": 227,
      "timestamp": 1760012829.754241,
      "duration": 6.960671663284302,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 722.79
    },
    {
      "iteration": 228,
      "timestamp": 1760012837.8363981,
      "duration": 8.08207654953003,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 721.74
    },
    {
      "iteration": 229,
      "timestamp": 1760012844.2429652,
      "duration": 6.4065327644348145,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 721.74
    },
    {
      "iteration": 230,
      "timestamp": 1760012852.2732816,
      "duration": 8.030276536941528,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.49
    },
    {
      "iteration": 231,
      "timestamp": 1760012859.6061246,
      "duration": 7.332456350326538,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 719.83
    },
    {
      "iteration": 232,
      "timestamp": 1760012866.4473188,
      "duration": 6.841161727905273,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 718.39
    },
    {
      "iteration": 233,
      "timestamp": 1760012873.9377894,
      "duration": 7.490438938140869,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 721.43
    },
    {
      "iteration": 234,
      "timestamp": 1760012880.2865014,
      "duration": 6.348684549331665,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 721.43
    },
    {
      "iteration": 235,
      "timestamp": 1760012887.7363353,
      "duration": 7.4498090744018555,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 721.65
    },
    {
      "iteration": 236,
      "timestamp": 1760012895.6430588,
      "duration": 7.906697750091553,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 721.65
    },
    {
      "iteration": 237,
      "timestamp": 1760012901.576992,
      "duration": 5.933900833129883,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 721.2
    },
    {
      "iteration": 238,
      "timestamp": 1760012909.031546,
      "duration": 7.454521656036377,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.83
    },
    {
      "iteration": 239,
      "timestamp": 1760012917.0730321,
      "duration": 8.041448593139648,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 723.82
    },
    {
      "iteration": 240,
      "timestamp": 1760012923.4111247,
      "duration": 6.338064432144165,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 723.82
    },
    {
      "iteration": 241,
      "timestamp": 1760012930.881084,
      "duration": 7.469578981399536,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 720.81
    },
    {
      "iteration": 242,
      "timestamp": 1760012938.001079,
      "duration": 7.119970798492432,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 720.81
    },
    {
      "iteration": 243,
      "timestamp": 1760012944.9411664,
      "duration": 6.940056562423706,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 720.81
    },
    {
      "iteration": 244,
      "timestamp": 1760012951.8517334,
      "duration": 6.9105329513549805,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 718.45
    },
    {
      "iteration": 245,
      "timestamp": 1760012959.3531065,
      "duration": 7.501348495483398,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 725.13
    },
    {
      "iteration": 246,
      "timestamp": 1760012966.816823,
      "duration": 7.463689804077148,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.93
    },
    {
      "iteration": 247,
      "timestamp": 1760012973.0533593,
      "duration": 6.236512899398804,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.93
    },
    {
      "iteration": 248,
      "timestamp": 1760012980.5863304,
      "duration": 7.532935619354248,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 728.32
    },
    {
      "iteration": 249,
      "timestamp": 1760012986.9244688,
      "duration": 6.3381028175354,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 728.32
    },
    {
      "iteration": 250,
      "timestamp": 1760012994.456433,
      "duration": 7.531930685043335,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 731.13
    },
    {
      "iteration": 251,
      "timestamp": 1760013002.4346943,
      "duration": 7.968935966491699,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.31
    },
    {
      "iteration": 252,
      "timestamp": 1760013008.26337,
      "duration": 5.82864785194397,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.31
    },
    {
      "iteration": 253,
      "timestamp": 1760013016.3321881,
      "duration": 8.068792343139648,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 723.37
    },
    {
      "iteration": 254,
      "timestamp": 1760013023.187789,
      "duration": 6.855572700500488,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 723.37
    },
    {
      "iteration": 255,
      "timestamp": 1760013030.1723258,
      "duration": 6.984509229660034,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 725.87
    },
    {
      "iteration": 256,
      "timestamp": 1760013038.1940873,
      "duration": 8.021736860275269,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 733.09
    },
    {
      "iteration": 257,
      "timestamp": 1760013044.0360148,
      "duration": 5.841897487640381,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 733.09
    },
    {
      "iteration": 258,
      "timestamp": 1760013052.314605,
      "duration": 8.278560161590576,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 731.91
    },
    {
      "iteration": 259,
      "timestamp": 1760013059.6798136,
      "duration": 7.365187883377075,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 735.7
    },
    {
      "iteration": 260,
      "timestamp": 1760013066.0717304,
      "duration": 6.391887903213501,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.69
    },
    {
      "iteration": 261,
      "timestamp": 1760013074.0890074,
      "duration": 8.017108917236328,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.4
    },
    {
      "iteration": 262,
      "timestamp": 1760013081.5260396,
      "duration": 7.437000751495361,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.4
    },
    {
      "iteration": 263,
      "timestamp": 1760013087.9530787,
      "duration": 6.42700982093811,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.4
    },
    {
      "iteration": 264,
      "timestamp": 1760013095.489619,
      "duration": 7.5365095138549805,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.4
    },
    {
      "iteration": 265,
      "timestamp": 1760013102.853521,
      "duration": 7.363875150680542,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 733.86
    },
    {
      "iteration": 266,
      "timestamp": 1760013109.2745795,
      "duration": 6.4210357666015625,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 742.56
    },
    {
      "iteration": 267,
      "timestamp": 1760013116.7135882,
      "duration": 7.438990354537964,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 742.46
    },
    {
      "iteration": 268,
      "timestamp": 1760013123.5062914,
      "duration": 6.792675256729126,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 741.19
    },
    {
      "iteration": 269,
      "timestamp": 1760013131.0207515,
      "duration": 7.514430284500122,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 740.58
    },
    {
      "iteration": 270,
      "timestamp": 1760013138.5164044,
      "duration": 7.495621681213379,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 743.41
    },
    {
      "iteration": 271,
      "timestamp": 1760013145.3596985,
      "duration": 6.842920303344727,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 743.07
    },
    {
      "iteration": 272,
      "timestamp": 1760013152.8271155,
      "duration": 7.467388868331909,
      "episodes_this_iter": 3,
      "num_episodes": 3,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 728.24
    },
    {
      "iteration": 273,
      "timestamp": 1760013159.765802,
      "duration": 6.938659906387329,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 728.24
    },
    {
      "iteration": 274,
      "timestamp": 1760013166.8930368,
      "duration": 7.127207517623901,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 726.56
    },
    {
      "iteration": 275,
      "timestamp": 1760013173.8405972,
      "duration": 6.947531461715698,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 726.56
    },
    {
      "iteration": 276,
      "timestamp": 1760013181.7854922,
      "duration": 7.944868803024292,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 728.96
    },
    {
      "iteration": 277,
      "timestamp": 1760013188.1124094,
      "duration": 6.3268914222717285,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.78
    },
    {
      "iteration": 278,
      "timestamp": 1760013195.6372864,
      "duration": 7.52485203742981,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 727.1
    },
    {
      "iteration": 279,
      "timestamp": 1760013203.5331812,
      "duration": 7.8958656787872314,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.86
    },
    {
      "iteration": 280,
      "timestamp": 1760013209.4315977,
      "duration": 5.898388624191284,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 724.86
    },
    {
      "iteration": 281,
      "timestamp": 1760013217.3428113,
      "duration": 7.9108405113220215,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 732.36
    },
    {
      "iteration": 282,
      "timestamp": 1760013223.1480422,
      "duration": 5.805211782455444,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 734.14
    },
    {
      "iteration": 283,
      "timestamp": 1760013231.2005327,
      "duration": 8.05243182182312,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 737.51
    },
    {
      "iteration": 284,
      "timestamp": 1760013239.2311537,
      "duration": 8.030587434768677,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 732.77
    },
    {
      "iteration": 285,
      "timestamp": 1760013246.1766708,
      "duration": 6.945491313934326,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 729.18
    },
    {
      "iteration": 286,
      "timestamp": 1760013253.1055934,
      "duration": 6.928900957107544,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 729.18
    },
    {
      "iteration": 287,
      "timestamp": 1760013260.1000645,
      "duration": 6.994445323944092,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 726.25
    },
    {
      "iteration": 288,
      "timestamp": 1760013267.027869,
      "duration": 6.927783727645874,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 726.25
    },
    {
      "iteration": 289,
      "timestamp": 1760013274.7113419,
      "duration": 7.6834495067596436,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 731.95
    },
    {
      "iteration": 290,
      "timestamp": 1760013281.108827,
      "duration": 6.397417306900024,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 731.93
    },
    {
      "iteration": 291,
      "timestamp": 1760013288.5503461,
      "duration": 7.441303491592407,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 734.21
    },
    {
      "iteration": 292,
      "timestamp": 1760013295.397631,
      "duration": 6.84725546836853,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 734.21
    },
    {
      "iteration": 293,
      "timestamp": 1760013302.3248954,
      "duration": 6.927217245101929,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 734.21
    },
    {
      "iteration": 294,
      "timestamp": 1760013310.4140055,
      "duration": 8.089056491851807,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 731.98
    },
    {
      "iteration": 295,
      "timestamp": 1760013317.3428864,
      "duration": 6.928858280181885,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 728.8
    },
    {
      "iteration": 296,
      "timestamp": 1760013324.3350303,
      "duration": 6.992112159729004,
      "episodes_this_iter": 2,
      "num_episodes": 2,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 736.39
    },
    {
      "iteration": 297,
      "timestamp": 1760013332.3294756,
      "duration": 7.99441933631897,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 736.39
    },
    {
      "iteration": 298,
      "timestamp": 1760013339.7763925,
      "duration": 7.446883201599121,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 738.5
    },
    {
      "iteration": 299,
      "timestamp": 1760013346.6583843,
      "duration": 6.881966829299927,
      "episodes_this_iter": 0,
      "num_episodes": 0,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 738.5
    },
    {
      "iteration": 300,
      "timestamp": 1760013354.2622957,
      "duration": 7.603879928588867,
      "episodes_this_iter": 1,
      "num_episodes": 1,
      "timesteps_total": 0,
      "timesteps_this_iter": 0,
      "episode_reward_mean": 0.0,
      "episode_len_mean": 740.48
    }
  ],
  "total_train_time": 2154.2820348739624,
  "end_time": "2025-10-09T20:35:54.271608"
}