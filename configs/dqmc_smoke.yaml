model:
  hidden: [256, 256]
learner:
  lr: 1.0e-3
  lambda_clip: 0.2
  batch_size: 8
  updates_per_iter: 1
rollout:
  epsilon_start: 1.0
  epsilon_end: 0.5
  epsilon_decay_steps: 100
  max_steps_per_episode: 20
training:
  num_episodes: 1
  checkpoint_every_updates: 1
